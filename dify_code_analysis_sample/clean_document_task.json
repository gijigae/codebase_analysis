{
    "highlights": "The key features of this code are:\n\n1. **Task Definition**: This code defines a Celery task called `clean_document_task` using the `@shared_task` decorator. Celery is a distributed task queue system that allows you to run tasks asynchronously.\n\n2. **Database Operations**: The code interacts with the database using the `db` object from the `extensions.ext_database` module. It retrieves a `Dataset` object, and then queries and deletes `DocumentSegment` objects related to the specified `document_id`.\n\n3. **Index Processor**: The code uses the `IndexProcessorFactory` to create an `IndexProcessor` object, which is then used to clean the index entries associated with the deleted document segments.\n\n4. **Logging and Exception Handling**: The code uses the `logging` module to log information about the task execution, including the start and end times. It also includes exception handling to log any errors that occur during the task execution.\n\n5. **Usage Example**: The code includes a comment that provides an example of how to use the `clean_document_task` function, which is to call the `delay()` method and pass the `document_id` and `dataset_id` as arguments.\n\nOverall, this code is responsible for cleaning up the database and index entries associated with a deleted document, which is a common task in document-based applications.",
    "overall_summary": "The provided code is a Python file named `clean_document_task.py` that contains a Celery task called `clean_document_task`. This task is responsible for cleaning up document data when a document is deleted.\n\nHere's a summary of the code:\n\n1. Imports:\n   - `logging` and `time` for logging and timing the task execution.\n   - `click` for providing colored console output.\n   - `celery` for using the `shared_task` decorator to define a Celery task.\n   - `IndexProcessorFactory` from `core.rag.index_processor.index_processor_factory` for initializing an index processor.\n   - `db` from `extensions.ext_database` for interacting with the database.\n   - `Dataset` and `DocumentSegment` from `models.dataset` for database models.\n\n2. The `clean_document_task` function is a Celery task that takes three parameters:\n   - `document_id`: The ID of the document to be cleaned up.\n   - `dataset_id`: The ID of the dataset the document belongs to.\n   - `doc_form`: The form of the document.\n\n3. The task performs the following actions:\n   - Retrieves the `Dataset` object for the given `dataset_id`.\n   - Retrieves all `DocumentSegment` objects associated with the `document_id`.\n   - If there are any `DocumentSegment` objects, it initializes an `IndexProcessor` using the `IndexProcessorFactory` and the `doc_form`.\n   - The `IndexProcessor` is used to clean up the index data for the associated `index_node_ids` from the `DocumentSegment` objects.\n   - The `DocumentSegment` objects are then deleted from the database.\n   - The changes are committed to the database.\n   - Logging is used to report the successful completion of the task and the latency.\n\n4. If any exceptions occur during the task execution, they are caught, and an error message is logged.\n\nIn summary, the `clean_document_task` is a Celery task that is responsible for cleaning up document data, including removing any associated index data and deleting the document segments, when a document is deleted.",
    "pseudocode": "Here's the high-level pythonic pseudocode for the `clean_document_task` function:\n\n```python\n# Define a Celery task function to clean up documents when they are deleted\n@shared_task(queue='dataset')\ndef clean_document_task(document_id: str, dataset_id: str, doc_form: str):\n    \"\"\"\n    Clean up document-related data when a document is deleted.\n\n    Args:\n        document_id (str): The ID of the document to be cleaned up.\n        dataset_id (str): The ID of the dataset the document belongs to.\n        doc_form (str): The form of the document.\n    \"\"\"\n    # Log the start of the task\n    logging.info(click.style(f'Start clean document when document deleted: {document_id}', fg='green'))\n    start_at = time.perf_counter()\n\n    try:\n        # Fetch the dataset the document belongs to\n        dataset = db.session.query(Dataset).filter(Dataset.id == dataset_id).first()\n\n        # Raise an exception if the document has no dataset\n        if not dataset:\n            raise Exception('Document has no dataset')\n\n        # Fetch all the segments associated with the document\n        segments = db.session.query(DocumentSegment).filter(DocumentSegment.document_id == document_id).all()\n\n        # If there are any segments, clean up the associated index nodes\n        if segments:\n            index_node_ids = [segment.index_node_id for segment in segments]\n            index_processor = IndexProcessorFactory(doc_form).init_index_processor()\n            index_processor.clean(dataset, index_node_ids)\n\n            # Delete all the segments associated with the document\n            for segment in segments:\n                db.session.delete(segment)\n\n            # Commit the database changes\n            db.session.commit()\n\n        # Log the successful completion of the task\n        end_at = time.perf_counter()\n        logging.info(\n            click.style(f'Cleaned document when document deleted: {document_id} latency: {end_at - start_at}', fg='green'))\n    except Exception:\n        # Log the failure of the task\n        logging.exception(\"Cleaned document when document deleted failed\")\n```\n\nThe key points of this pseudocode are:\n\n1. The function is defined as a Celery task, which allows it to be executed asynchronously in the background.\n2. The function takes three parameters: the ID of the document to be cleaned up, the ID of the dataset the document belongs to, and the form of the document.\n3. The function first logs the start of the task and records the start time.\n4. It then fetches the dataset the document belongs to, and raises an exception if the document has no dataset.\n5. It fetches all the segments associated with the document, and if there are any, it cleans up the associated index nodes using the `IndexProcessorFactory` and deletes all the segments.\n6. The database changes are then committed.\n7. The function logs the successful completion of the task and the time it took to execute.\n8. If any exceptions occur during the task, the function logs the failure.\n\nThis pseudocode provides a high-level overview of the logic behind the `clean_document_task` function, without getting into the specific implementation details.",
    "import_relationships": "Imports found:\nimport logging\nimport time\nimport click\nfrom celery import shared_task\nfrom core.rag.index_processor.index_processor_factory import IndexProcessorFactory\nfrom extensions.ext_database import db\nfrom models.dataset import Dataset, DocumentSegment"
}